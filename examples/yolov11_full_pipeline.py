"""
ClearML YOLOv11 Full Pipeline Example
=====================================
ClearMLì˜ ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì„ í™œìš©í•˜ëŠ” ì¢…í•© ì˜ˆì œ

Features:
â”œâ”€â”€ 1. Task Management (ì‹¤í—˜ ì¶”ì )
â”œâ”€â”€ 2. Dataset Versioning (ë°ì´í„°ì…‹ ë²„ì „ ê´€ë¦¬)
â”œâ”€â”€ 3. Hyperparameter Optimization (HPO)
â”œâ”€â”€ 4. Pipeline Orchestration (íŒŒì´í”„ë¼ì¸)
â”œâ”€â”€ 5. Model Registry (ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬)
â”œâ”€â”€ 6. Model Serving (ëª¨ë¸ ì„œë¹™)
â”œâ”€â”€ 7. Artifacts Management (ì•„í‹°íŒ©íŠ¸ ê´€ë¦¬)
â”œâ”€â”€ 8. Scalars & Plots (ë©”íŠ¸ë¦­ ì‹œê°í™”)
â”œâ”€â”€ 9. Debug Samples (ë””ë²„ê·¸ ìƒ˜í”Œ)
â””â”€â”€ 10. Remote Execution (ì›ê²© ì‹¤í–‰)

ì‚¬ìš©ë²•:
1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰:
   python yolov11_full_pipeline.py --mode pipeline

2. ë°ì´í„°ì…‹ ì—…ë¡œë“œ:
   python yolov11_full_pipeline.py --mode dataset --data-path /path/to/dataset

3. í•™ìŠµë§Œ ì‹¤í–‰:
   python yolov11_full_pipeline.py --mode train

4. HPO ì‹¤í–‰:
   python yolov11_full_pipeline.py --mode hpo

5. ëª¨ë¸ ì„œë¹™:
   python yolov11_full_pipeline.py --mode serve --model-id <model_id>

6. ì›ê²© ì‹¤í–‰:
   clearml-task --project Manifest-Vision --name yolov11-pipeline \
                --script examples/yolov11_full_pipeline.py --queue vision
"""

import os
import sys
import json
import argparse
import tempfile
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, List

# ===========================================
# ClearML Imports
# ===========================================
from clearml import (
    Task,
    Logger,
    Dataset,
    Model,
    PipelineController,
    PipelineDecorator,
    TaskTypes,
    OutputModel,
    InputModel,
)
from clearml.automation import (
    UniformParameterRange,
    UniformIntegerParameterRange,
    DiscreteParameterRange,
    HyperParameterOptimizer,
    GridSearch,
    RandomSearch,
    OptimizerBOHB,
)

# ===========================================
# ClearML ì„œë²„ ì¸ì¦ ì„¤ì •
# ===========================================
Task.set_credentials(
    api_host="https://83f837d6923d.ngrok-free.app",
    web_host="http://localhost:8080",
    files_host="http://localhost:8081",
    key="Kj7mNp2xQw9rTs5vYb3uLc8h",
    secret="Xf4kMn7pQr2sTv5wYb8zCd3eGh6jKm9nPq2rSt5uVx8y"
)


# ###########################################
# #  1. DATASET VERSIONING (ë°ì´í„°ì…‹ ë²„ì „ ê´€ë¦¬)
# ###########################################

def create_dataset(
    data_path: str,
    dataset_name: str = "YOLOv11-Dataset",
    dataset_project: str = "Manifest-Vision/Datasets",
    description: str = "YOLOv11 Object Detection Dataset"
) -> str:
    """
    ë°ì´í„°ì…‹ì„ ClearMLì— ì—…ë¡œë“œí•˜ê³  ë²„ì „ ê´€ë¦¬
    
    ClearML Dataset ê¸°ëŠ¥:
    - ë°ì´í„° ë²„ì „ ê´€ë¦¬ (Gitì²˜ëŸ¼ ë³€ê²½ ì¶”ì )
    - ëŒ€ìš©ëŸ‰ íŒŒì¼ íš¨ìœ¨ì  ì €ì¥
    - ë°ì´í„° ê³„ë³´(lineage) ì¶”ì 
    - íŒ€ ê°„ ë°ì´í„° ê³µìœ 
    """
    print("\n" + "="*60)
    print("ğŸ“¦ Creating ClearML Dataset")
    print("="*60)
    
    # ìƒˆ ë°ì´í„°ì…‹ ìƒì„±
    dataset = Dataset.create(
        dataset_name=dataset_name,
        dataset_project=dataset_project,
        description=description,
        dataset_tags=["yolov11", "object-detection", "v1"]
    )
    
    # ë°ì´í„° íŒŒì¼ ì¶”ê°€
    data_path = Path(data_path)
    if data_path.is_dir():
        dataset.add_files(
            path=str(data_path),
            dataset_path="data/",
            recursive=True
        )
        print(f"  âœ“ Added directory: {data_path}")
    else:
        dataset.add_files(path=str(data_path))
        print(f"  âœ“ Added file: {data_path}")
    
    # ë©”íƒ€ë°ì´í„° ì¶”ê°€
    dataset.set_metadata({
        "created_by": os.environ.get("USER", "unknown"),
        "created_at": datetime.now().isoformat(),
        "format": "YOLO",
        "source": str(data_path)
    })
    
    # ë°ì´í„°ì…‹ ì—…ë¡œë“œ ë° ì™„ë£Œ
    dataset.upload(
        output_url=None,  # ê¸°ë³¸ íŒŒì¼ ì„œë²„ ì‚¬ìš©
        verbose=True
    )
    dataset.finalize()
    
    dataset_id = dataset.id
    print(f"\nâœ… Dataset created successfully!")
    print(f"   ID: {dataset_id}")
    print(f"   Name: {dataset_name}")
    print(f"   Project: {dataset_project}")
    
    return dataset_id


def get_dataset(
    dataset_id: Optional[str] = None,
    dataset_name: Optional[str] = None,
    dataset_project: str = "Manifest-Vision/Datasets"
) -> str:
    """
    ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ë¡œì»¬ ê²½ë¡œ ë°˜í™˜
    """
    print("\nğŸ“¥ Fetching dataset from ClearML...")
    
    if dataset_id:
        dataset = Dataset.get(dataset_id=dataset_id)
    else:
        dataset = Dataset.get(
            dataset_project=dataset_project,
            dataset_name=dataset_name,
            only_published=True  # ë°°í¬ëœ ë²„ì „ë§Œ
        )
    
    # ë¡œì»¬ì— ìºì‹œëœ ê²½ë¡œ ë°˜í™˜
    local_path = dataset.get_local_copy()
    print(f"  âœ“ Dataset cached at: {local_path}")
    
    return local_path


# ###########################################
# #  2. TRAINING WITH FULL LOGGING
# ###########################################

def train_model(
    dataset_id: Optional[str] = None,
    data_yaml: Optional[str] = None,
    parent_task_id: Optional[str] = None
) -> Dict[str, Any]:
    """
    ClearMLì˜ ëª¨ë“  ë¡œê¹… ê¸°ëŠ¥ì„ í™œìš©í•œ í•™ìŠµ
    
    ClearML Logging ê¸°ëŠ¥:
    - Scalars: Loss, Accuracy ë“± ìˆ˜ì¹˜ ë©”íŠ¸ë¦­
    - Plots: Confusion Matrix, PR Curve ë“± ì°¨íŠ¸
    - Debug Samples: ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ ìƒ˜í”Œ
    - Artifacts: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸, ì„¤ì • íŒŒì¼ ë“±
    - Console Logs: ì‹¤ì‹œê°„ ì½˜ì†” ì¶œë ¥
    """
    
    # Task ì´ˆê¸°í™”
    task = Task.init(
        project_name="Manifest-Vision",
        task_name="YOLOv11-Training-Full",
        task_type=TaskTypes.training,
        tags=["yolov11", "full-pipeline", "production"],
        reuse_last_task_id=False,  # í•­ìƒ ìƒˆ Task ìƒì„±
        auto_connect_frameworks={
            "pytorch": True,
            "matplotlib": True,
            "tensorboard": True,
        }
    )
    
    # ë¶€ëª¨ Task ì—°ê²° (íŒŒì´í”„ë¼ì¸ìš©)
    if parent_task_id:
        task.set_parent(parent_task_id)
    
    # ===========================================
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (UIì—ì„œ ìˆ˜ì • ê°€ëŠ¥)
    # ===========================================
    model_config = {
        "variant": "yolo11s.pt",
        "pretrained": True,
    }
    
    training_config = {
        "epochs": 100,
        "batch_size": 16,
        "imgsz": 640,
        "optimizer": "AdamW",
        "lr0": 0.001,
        "lrf": 0.01,
        "momentum": 0.937,
        "weight_decay": 0.0005,
        "warmup_epochs": 3,
        "patience": 50,
        "workers": 4,
        "cache": False,
    }
    
    augmentation_config = {
        "hsv_h": 0.015,
        "hsv_s": 0.7,
        "hsv_v": 0.4,
        "degrees": 0.0,
        "translate": 0.1,
        "scale": 0.5,
        "shear": 0.0,
        "perspective": 0.0,
        "flipud": 0.0,
        "fliplr": 0.5,
        "mosaic": 1.0,
        "mixup": 0.0,
    }
    
    # ClearMLì— íŒŒë¼ë¯¸í„° ì—°ê²°
    task.connect(model_config, name="model")
    task.connect(training_config, name="training")
    task.connect(augmentation_config, name="augmentation")
    
    # Logger ì´ˆê¸°í™”
    logger = Logger.current_logger()
    
    # ===========================================
    # ì‹œìŠ¤í…œ ì •ë³´ ë¡œê¹…
    # ===========================================
    import torch
    
    system_info = {
        "python_version": sys.version,
        "pytorch_version": torch.__version__,
        "cuda_available": torch.cuda.is_available(),
        "cuda_version": torch.version.cuda if torch.cuda.is_available() else None,
        "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,
        "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
    }
    task.connect(system_info, name="system")
    
    print("\n" + "="*60)
    print("ğŸš€ Starting YOLOv11 Training with Full ClearML Integration")
    print("="*60)
    for key, value in system_info.items():
        print(f"  {key}: {value}")
    
    # ===========================================
    # ë°ì´í„°ì…‹ ë¡œë“œ
    # ===========================================
    if dataset_id:
        data_path = get_dataset(dataset_id=dataset_id)
        data_yaml = Path(data_path) / "data" / "dataset.yaml"
    elif data_yaml:
        data_yaml = Path(data_yaml)
    else:
        print("âš  No dataset specified. Using default.")
        data_yaml = Path("data/dataset.yaml")
    
    if not data_yaml.exists():
        print(f"âŒ Dataset YAML not found: {data_yaml}")
        # ë°ëª¨ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±
        print("  Creating dummy dataset for demo...")
        task.set_parameter("training/epochs", 1)
        training_config["epochs"] = 1
    
    # ===========================================
    # Ultralytics ì½œë°±ìœ¼ë¡œ ClearML ë¡œê¹…
    # ===========================================
    from ultralytics import YOLO
    from ultralytics.utils.callbacks.clearml import callbacks as clearml_callbacks
    
    # ì»¤ìŠ¤í…€ ì½œë°± ì •ì˜
    def on_train_epoch_end(trainer):
        """ì—í­ ì¢…ë£Œ ì‹œ ì¶”ê°€ ë¡œê¹…"""
        epoch = trainer.epoch
        
        # í•™ìŠµ ë©”íŠ¸ë¦­ ë¡œê¹…
        if hasattr(trainer, 'metrics'):
            for key, value in trainer.metrics.items():
                logger.report_scalar(
                    title="Training Metrics",
                    series=key,
                    value=float(value),
                    iteration=epoch
                )
        
        # GPU ë©”ëª¨ë¦¬ ë¡œê¹…
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated() / 1e9
            logger.report_scalar(
                title="System",
                series="GPU Memory (GB)",
                value=gpu_memory,
                iteration=epoch
            )
    
    def on_val_end(validator):
        """ê²€ì¦ ì¢…ë£Œ ì‹œ ì¶”ê°€ ë¡œê¹…"""
        # Confusion Matrix ë¡œê¹…
        if hasattr(validator, 'confusion_matrix'):
            cm = validator.confusion_matrix.matrix
            logger.report_confusion_matrix(
                title="Confusion Matrix",
                series="Validation",
                matrix=cm.tolist(),
                xlabels=validator.names,
                ylabels=validator.names,
            )
    
    def on_train_end(trainer):
        """í•™ìŠµ ì™„ë£Œ ì‹œ ìµœì¢… ë¡œê¹…"""
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        logger.report_text(
            "Training completed successfully!",
            level=Logger.LogLevel.INFO
        )
    
    # ëª¨ë¸ ë¡œë“œ
    model = YOLO(model_config["variant"])
    
    # ì½œë°± ë“±ë¡
    model.add_callback("on_train_epoch_end", on_train_epoch_end)
    model.add_callback("on_val_end", on_val_end)
    model.add_callback("on_train_end", on_train_end)
    
    # ===========================================
    # í•™ìŠµ ì‹¤í–‰
    # ===========================================
    device = 0 if torch.cuda.is_available() else "cpu"
    
    results = model.train(
        data=str(data_yaml) if data_yaml.exists() else None,
        epochs=training_config["epochs"],
        imgsz=training_config["imgsz"],
        batch=training_config["batch_size"],
        device=device,
        workers=training_config["workers"],
        cache=training_config["cache"],
        optimizer=training_config["optimizer"],
        lr0=training_config["lr0"],
        lrf=training_config["lrf"],
        momentum=training_config["momentum"],
        weight_decay=training_config["weight_decay"],
        warmup_epochs=training_config["warmup_epochs"],
        patience=training_config["patience"],
        # Augmentation
        hsv_h=augmentation_config["hsv_h"],
        hsv_s=augmentation_config["hsv_s"],
        hsv_v=augmentation_config["hsv_v"],
        degrees=augmentation_config["degrees"],
        translate=augmentation_config["translate"],
        scale=augmentation_config["scale"],
        flipud=augmentation_config["flipud"],
        fliplr=augmentation_config["fliplr"],
        mosaic=augmentation_config["mosaic"],
        mixup=augmentation_config["mixup"],
        # Output
        project="runs/train",
        name=f"exp_{task.id[:8]}",
        exist_ok=True,
        plots=True,
        save=True,
    )
    
    # ===========================================
    # ê²°ê³¼ ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ
    # ===========================================
    exp_dir = Path(f"runs/train/exp_{task.id[:8]}")
    
    # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì—…ë¡œë“œ
    best_model = exp_dir / "weights" / "best.pt"
    last_model = exp_dir / "weights" / "last.pt"
    
    if best_model.exists():
        # OutputModelë¡œ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
        output_model = OutputModel(
            task=task,
            name="YOLOv11-Best",
            framework="PyTorch",
            tags=["yolov11", "best", "production-ready"]
        )
        output_model.update_weights(
            weights_filename=str(best_model),
            auto_delete_file=False
        )
        output_model.update_design(config_dict=model_config)
        
        task.upload_artifact("best_model", artifact_object=str(best_model))
        print(f"âœ“ Best model uploaded to Model Registry")
    
    if last_model.exists():
        task.upload_artifact("last_model", artifact_object=str(last_model))
    
    # í•™ìŠµ ê²°ê³¼ ì´ë¯¸ì§€ ì—…ë¡œë“œ
    for img_file in exp_dir.glob("*.png"):
        logger.report_image(
            title="Training Results",
            series=img_file.stem,
            local_path=str(img_file)
        )
    
    # í•™ìŠµ ì„¤ì • ì•„í‹°íŒ©íŠ¸
    config_artifact = {
        "model": model_config,
        "training": training_config,
        "augmentation": augmentation_config,
    }
    task.upload_artifact("training_config", artifact_object=config_artifact)
    
    # ===========================================
    # ìµœì¢… ê²°ê³¼
    # ===========================================
    final_results = {
        "task_id": task.id,
        "model_path": str(best_model) if best_model.exists() else None,
        "metrics": results.results_dict if hasattr(results, 'results_dict') else {},
    }
    
    # Summary ë©”íŠ¸ë¦­
    if hasattr(results, 'results_dict'):
        for key, value in results.results_dict.items():
            if isinstance(value, (int, float)):
                logger.report_single_value(key, float(value))
    
    print("\n" + "="*60)
    print("âœ… Training completed!")
    print(f"   Task ID: {task.id}")
    print(f"   Best Model: {best_model}")
    print("="*60)
    
    return final_results


# ###########################################
# #  3. HYPERPARAMETER OPTIMIZATION (HPO)
# ###########################################

def run_hpo(
    base_task_id: Optional[str] = None,
    max_trials: int = 20,
    concurrent_trials: int = 2
):
    """
    ClearML Hyperparameter Optimization
    
    HPO ê¸°ëŠ¥:
    - Grid Search: ëª¨ë“  ì¡°í•© íƒìƒ‰
    - Random Search: ë¬´ì‘ìœ„ ìƒ˜í”Œë§
    - BOHB: Bayesian Optimization + Hyperband
    - Optuna: Optuna ë°±ì—”ë“œ ì§€ì›
    """
    print("\n" + "="*60)
    print("ğŸ” Starting Hyperparameter Optimization")
    print("="*60)
    
    # HPO Controller Task ìƒì„±
    task = Task.init(
        project_name="Manifest-Vision",
        task_name="YOLOv11-HPO",
        task_type=TaskTypes.optimizer,
        tags=["hpo", "yolov11", "optimization"]
    )
    
    # ê¸°ë³¸ í•™ìŠµ Task (í´ë¡ í•  í…œí”Œë¦¿)
    if not base_task_id:
        # ì´ì „ í•™ìŠµ Task ì°¾ê¸°
        tasks = Task.get_tasks(
            project_name="Manifest-Vision",
            task_name="YOLOv11-Training-Full",
            task_filter={"status": ["completed"]}
        )
        if tasks:
            base_task_id = tasks[0].id
        else:
            print("âŒ No base task found. Please train a model first.")
            return
    
    # HPO ì„¤ì •
    optimizer = HyperParameterOptimizer(
        base_task_id=base_task_id,
        
        # íƒìƒ‰í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜
        hyper_parameters=[
            # í•™ìŠµë¥  íƒìƒ‰
            UniformParameterRange(
                name="training/lr0",
                min_value=0.0001,
                max_value=0.01,
                step_size=0.0001
            ),
            # ë°°ì¹˜ ì‚¬ì´ì¦ˆ íƒìƒ‰
            DiscreteParameterRange(
                name="training/batch_size",
                values=[8, 16, 32, 64]
            ),
            # ì˜µí‹°ë§ˆì´ì € ì„ íƒ
            DiscreteParameterRange(
                name="training/optimizer",
                values=["SGD", "Adam", "AdamW"]
            ),
            # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ
            DiscreteParameterRange(
                name="training/imgsz",
                values=[416, 512, 640]
            ),
            # Augmentation ê°•ë„
            UniformParameterRange(
                name="augmentation/mosaic",
                min_value=0.0,
                max_value=1.0,
                step_size=0.1
            ),
        ],
        
        # ìµœì í™” ëª©í‘œ
        objective_metric_title="metrics",
        objective_metric_series="mAP50-95",
        objective_metric_sign="max",  # ìµœëŒ€í™”
        
        # íƒìƒ‰ ì „ëµ
        optimizer_class=OptimizerBOHB,  # Bayesian Optimization
        
        # ì‹¤í–‰ ì„¤ì •
        max_number_of_concurrent_tasks=concurrent_trials,
        total_max_jobs=max_trials,
        min_iteration_per_job=10,
        max_iteration_per_job=100,
        
        # ì‹¤í–‰ í
        execution_queue="vision",
        
        # ë¦¬ì†ŒìŠ¤
        compute_time_limit=None,
        pool_period_min=1,
    )
    
    # HPO ì‹œì‘
    optimizer.start()
    
    print(f"âœ“ HPO started with {max_trials} trials")
    print(f"  Concurrent trials: {concurrent_trials}")
    print(f"  Base task: {base_task_id}")
    
    # ì™„ë£Œ ëŒ€ê¸° (ì˜µì…˜)
    # optimizer.wait()
    
    # ìƒìœ„ ê²°ê³¼ í™•ì¸
    # top_experiments = optimizer.get_top_experiments(top_k=5)
    
    return optimizer


# ###########################################
# #  4. PIPELINE ORCHESTRATION
# ###########################################

@PipelineDecorator.component(
    return_values=["dataset_id"],
    cache=True,
    task_type=TaskTypes.data_processing
)
def pipeline_step_prepare_data(data_path: str) -> str:
    """íŒŒì´í”„ë¼ì¸ Step 1: ë°ì´í„° ì¤€ë¹„"""
    dataset_id = create_dataset(data_path)
    return dataset_id


@PipelineDecorator.component(
    return_values=["model_path", "metrics"],
    cache=False,
    task_type=TaskTypes.training
)
def pipeline_step_train(dataset_id: str) -> tuple:
    """íŒŒì´í”„ë¼ì¸ Step 2: ëª¨ë¸ í•™ìŠµ"""
    results = train_model(dataset_id=dataset_id)
    return results["model_path"], results["metrics"]


@PipelineDecorator.component(
    return_values=["eval_results"],
    cache=False,
    task_type=TaskTypes.testing
)
def pipeline_step_evaluate(model_path: str, dataset_id: str) -> dict:
    """íŒŒì´í”„ë¼ì¸ Step 3: ëª¨ë¸ í‰ê°€"""
    from ultralytics import YOLO
    
    model = YOLO(model_path)
    data_path = get_dataset(dataset_id=dataset_id)
    
    results = model.val(
        data=Path(data_path) / "data" / "dataset.yaml",
        split="test"
    )
    
    eval_results = {
        "mAP50": float(results.box.map50),
        "mAP50-95": float(results.box.map),
        "precision": float(results.box.mp),
        "recall": float(results.box.mr),
    }
    
    return eval_results


@PipelineDecorator.component(
    return_values=["model_id"],
    cache=False,
    task_type=TaskTypes.custom
)
def pipeline_step_register_model(
    model_path: str,
    metrics: dict,
    min_map: float = 0.5
) -> Optional[str]:
    """íŒŒì´í”„ë¼ì¸ Step 4: ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡"""
    
    # í’ˆì§ˆ ê²Œì´íŠ¸
    if metrics.get("mAP50-95", 0) < min_map:
        print(f"âš  Model quality below threshold ({min_map}). Skipping registration.")
        return None
    
    # ëª¨ë¸ ë“±ë¡
    from clearml import Model
    
    model = Model.create(
        name="YOLOv11-Production",
        project="Manifest-Vision/Models",
        tags=["production", "yolov11", "approved"],
        framework="PyTorch"
    )
    
    model.update_weights(weights_filename=model_path)
    model.update_labels({"classes": ["class1", "class2"]})  # í´ë˜ìŠ¤ ëª©ë¡
    
    # ë°°í¬ ê°€ëŠ¥ìœ¼ë¡œ ë§ˆí‚¹
    model.publish()
    
    print(f"âœ“ Model registered: {model.id}")
    return model.id


@PipelineDecorator.pipeline(
    name="YOLOv11-Training-Pipeline",
    project="Manifest-Vision/Pipelines",
    version="1.0.0",
    pipeline_execution_queue="vision",
    default_queue="vision"
)
def run_training_pipeline(data_path: str, min_map: float = 0.5):
    """
    ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸
    
    Pipeline:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Prepare    â”‚â”€â”€â”€â–¶â”‚   Train     â”‚â”€â”€â”€â–¶â”‚  Evaluate   â”‚â”€â”€â”€â–¶â”‚  Register   â”‚
    â”‚   Data      â”‚    â”‚   Model     â”‚    â”‚   Model     â”‚    â”‚   Model     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    print("\n" + "="*60)
    print("ğŸ”„ Starting YOLOv11 Training Pipeline")
    print("="*60)
    
    # Step 1: ë°ì´í„° ì¤€ë¹„
    dataset_id = pipeline_step_prepare_data(data_path)
    
    # Step 2: ëª¨ë¸ í•™ìŠµ
    model_path, metrics = pipeline_step_train(dataset_id)
    
    # Step 3: ëª¨ë¸ í‰ê°€
    eval_results = pipeline_step_evaluate(model_path, dataset_id)
    
    # Step 4: ëª¨ë¸ ë“±ë¡ (í’ˆì§ˆ ê²Œì´íŠ¸ í†µê³¼ ì‹œ)
    model_id = pipeline_step_register_model(model_path, eval_results, min_map)
    
    return model_id


def run_pipeline_controller(data_path: str):
    """
    PipelineControllerë¥¼ ì‚¬ìš©í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    (ë” ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš°)
    """
    pipe = PipelineController(
        name="YOLOv11-Pipeline-Controlled",
        project="Manifest-Vision/Pipelines",
        version="1.0.0",
        add_pipeline_tags=True,
    )
    
    # Step ì •ì˜
    pipe.add_step(
        name="prepare_data",
        base_task_project="Manifest-Vision",
        base_task_name="Data-Preparation",
        parameter_override={
            "General/data_path": data_path
        }
    )
    
    pipe.add_step(
        name="train_model",
        base_task_project="Manifest-Vision",
        base_task_name="YOLOv11-Training-Full",
        parents=["prepare_data"],
        parameter_override={
            "General/dataset_id": "${prepare_data.dataset_id}"
        }
    )
    
    pipe.add_step(
        name="evaluate",
        base_task_project="Manifest-Vision",
        base_task_name="Model-Evaluation",
        parents=["train_model"],
        parameter_override={
            "General/model_path": "${train_model.model_path}"
        }
    )
    
    # íŒŒì´í”„ë¼ì¸ ì‹œì‘
    pipe.start(queue="vision")
    
    return pipe


# ###########################################
# #  5. MODEL SERVING
# ###########################################

def serve_model(
    model_id: Optional[str] = None,
    model_path: Optional[str] = None,
    port: int = 8000
):
    """
    ClearML Model Serving
    
    ì„œë¹™ ì˜µì…˜:
    1. ClearML Serving: í”„ë¡œë•ì…˜ ì„œë¹™ ì¸í”„ë¼
    2. Triton Inference Server: ê³ ì„±ëŠ¥ ì¶”ë¡ 
    3. Custom FastAPI: ì»¤ìŠ¤í…€ REST API
    """
    print("\n" + "="*60)
    print("ğŸš€ Starting Model Serving")
    print("="*60)
    
    # ëª¨ë¸ ë¡œë“œ
    if model_id:
        # ClearML Model Registryì—ì„œ ë¡œë“œ
        model = Model(model_id=model_id)
        model_path = model.get_local_copy()
        print(f"âœ“ Model loaded from registry: {model_id}")
    elif model_path:
        print(f"âœ“ Using local model: {model_path}")
    else:
        print("âŒ No model specified")
        return
    
    # FastAPI ì„œë¹™ ì˜ˆì œ
    try:
        from fastapi import FastAPI, UploadFile, File
        from fastapi.responses import JSONResponse
        import uvicorn
        from PIL import Image
        import io
        
        app = FastAPI(
            title="YOLOv11 Inference API",
            description="ClearML Model Serving Example",
            version="1.0.0"
        )
        
        # ëª¨ë¸ ë¡œë“œ
        from ultralytics import YOLO
        yolo_model = YOLO(model_path)
        
        @app.get("/health")
        def health_check():
            return {"status": "healthy", "model": model_path}
        
        @app.post("/predict")
        async def predict(file: UploadFile = File(...)):
            """ì´ë¯¸ì§€ ì¶”ë¡ """
            # ì´ë¯¸ì§€ ì½ê¸°
            contents = await file.read()
            image = Image.open(io.BytesIO(contents))
            
            # ì¶”ë¡ 
            results = yolo_model(image)
            
            # ê²°ê³¼ íŒŒì‹±
            predictions = []
            for r in results:
                boxes = r.boxes
                for box in boxes:
                    predictions.append({
                        "class": int(box.cls),
                        "class_name": yolo_model.names[int(box.cls)],
                        "confidence": float(box.conf),
                        "bbox": box.xyxy.tolist()[0]
                    })
            
            return JSONResponse({
                "predictions": predictions,
                "count": len(predictions)
            })
        
        @app.post("/batch_predict")
        async def batch_predict(files: List[UploadFile] = File(...)):
            """ë°°ì¹˜ ì¶”ë¡ """
            all_predictions = []
            
            for file in files:
                contents = await file.read()
                image = Image.open(io.BytesIO(contents))
                results = yolo_model(image)
                
                file_predictions = []
                for r in results:
                    boxes = r.boxes
                    for box in boxes:
                        file_predictions.append({
                            "class": int(box.cls),
                            "class_name": yolo_model.names[int(box.cls)],
                            "confidence": float(box.conf),
                            "bbox": box.xyxy.tolist()[0]
                        })
                
                all_predictions.append({
                    "filename": file.filename,
                    "predictions": file_predictions
                })
            
            return JSONResponse({"results": all_predictions})
        
        print(f"\nğŸŒ Starting server on http://0.0.0.0:{port}")
        print("   Endpoints:")
        print("   - GET  /health        - Health check")
        print("   - POST /predict       - Single image inference")
        print("   - POST /batch_predict - Batch inference")
        print("\n   Press Ctrl+C to stop")
        
        uvicorn.run(app, host="0.0.0.0", port=port)
        
    except ImportError:
        print("âš  FastAPI not installed. Install with: pip install fastapi uvicorn python-multipart")
        print("\nAlternative: Use ClearML Serving")
        print("  clearml-serving create --name yolov11-serving")
        print("  clearml-serving model add --model-id", model_id or "<model_id>")


# ###########################################
# #  6. MODEL COMPARISON & A/B TESTING
# ###########################################

def compare_models(model_ids: List[str]):
    """
    ì—¬ëŸ¬ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
    """
    print("\n" + "="*60)
    print("ğŸ“Š Model Comparison")
    print("="*60)
    
    task = Task.init(
        project_name="Manifest-Vision",
        task_name="Model-Comparison",
        task_type=TaskTypes.testing
    )
    
    logger = Logger.current_logger()
    
    comparison_results = []
    
    for model_id in model_ids:
        model = Model(model_id=model_id)
        model_path = model.get_local_copy()
        
        from ultralytics import YOLO
        yolo = YOLO(model_path)
        
        # ê²€ì¦ ì‹¤í–‰
        results = yolo.val()
        
        metrics = {
            "model_id": model_id,
            "model_name": model.name,
            "mAP50": float(results.box.map50),
            "mAP50-95": float(results.box.map),
            "precision": float(results.box.mp),
            "recall": float(results.box.mr),
        }
        comparison_results.append(metrics)
        
        # ì°¨íŠ¸ì— ì¶”ê°€
        for metric_name, value in metrics.items():
            if isinstance(value, (int, float)):
                logger.report_scalar(
                    title="Model Comparison",
                    series=model.name,
                    value=value,
                    iteration=model_ids.index(model_id)
                )
    
    # ë¹„êµ í…Œì´ë¸” ìƒì„±
    import pandas as pd
    df = pd.DataFrame(comparison_results)
    
    logger.report_table(
        title="Model Comparison Table",
        series="All Models",
        table_plot=df
    )
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
    best_model = max(comparison_results, key=lambda x: x["mAP50-95"])
    logger.report_single_value("Best Model ID", best_model["model_id"])
    
    print(f"\nâœ“ Best model: {best_model['model_name']}")
    print(f"  mAP50-95: {best_model['mAP50-95']:.4f}")
    
    return comparison_results


# ###########################################
# #  7. REMOTE EXECUTION HELPERS
# ###########################################

def execute_remotely(queue: str = "vision"):
    """
    í˜„ì¬ Taskë¥¼ ì›ê²© Agentë¡œ ì „ì†¡
    
    ì´ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì¦‰ì‹œ ì¢…ë£Œë˜ê³ ,
    ì§€ì •ëœ íì˜ Agentê°€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•¨
    """
    task = Task.init(
        project_name="Manifest-Vision",
        task_name="Remote-Execution-Example"
    )
    
    # ì›ê²© ì‹¤í–‰ ëª¨ë“œ ì „í™˜
    # ì´ ì‹œì ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì¢…ë£Œë˜ê³  Agentê°€ ì´ì–´ë°›ìŒ
    task.execute_remotely(queue_name=queue)
    
    print("This code runs on the remote agent!")
    # ... ì´í›„ ì½”ë“œëŠ” ì›ê²© Agentì—ì„œ ì‹¤í–‰ë¨


# ###########################################
# #  MAIN ENTRY POINT
# ###########################################

def main():
    parser = argparse.ArgumentParser(
        description="ClearML YOLOv11 Full Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # ë°ì´í„°ì…‹ ì—…ë¡œë“œ
  python yolov11_full_pipeline.py --mode dataset --data-path ./data

  # ëª¨ë¸ í•™ìŠµ
  python yolov11_full_pipeline.py --mode train

  # HPO ì‹¤í–‰
  python yolov11_full_pipeline.py --mode hpo --max-trials 10

  # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
  python yolov11_full_pipeline.py --mode pipeline --data-path ./data

  # ëª¨ë¸ ì„œë¹™
  python yolov11_full_pipeline.py --mode serve --model-id <id>

  # ëª¨ë¸ ë¹„êµ
  python yolov11_full_pipeline.py --mode compare --model-ids id1,id2,id3
        """
    )
    
    parser.add_argument(
        "--mode",
        type=str,
        required=True,
        choices=["dataset", "train", "hpo", "pipeline", "serve", "compare"],
        help="ì‹¤í–‰ ëª¨ë“œ"
    )
    parser.add_argument("--data-path", type=str, help="ë°ì´í„°ì…‹ ê²½ë¡œ")
    parser.add_argument("--data-yaml", type=str, help="ë°ì´í„°ì…‹ YAML ê²½ë¡œ")
    parser.add_argument("--dataset-id", type=str, help="ClearML ë°ì´í„°ì…‹ ID")
    parser.add_argument("--model-id", type=str, help="ëª¨ë¸ ID")
    parser.add_argument("--model-ids", type=str, help="ë¹„êµí•  ëª¨ë¸ ID ëª©ë¡ (ì‰¼í‘œ êµ¬ë¶„)")
    parser.add_argument("--max-trials", type=int, default=20, help="HPO ìµœëŒ€ ì‹œë„ íšŸìˆ˜")
    parser.add_argument("--port", type=int, default=8000, help="ì„œë¹™ í¬íŠ¸")
    
    args = parser.parse_args()
    
    if args.mode == "dataset":
        if not args.data_path:
            print("âŒ --data-path required for dataset mode")
            sys.exit(1)
        create_dataset(args.data_path)
    
    elif args.mode == "train":
        train_model(
            dataset_id=args.dataset_id,
            data_yaml=args.data_yaml
        )
    
    elif args.mode == "hpo":
        run_hpo(max_trials=args.max_trials)
    
    elif args.mode == "pipeline":
        if not args.data_path:
            print("âŒ --data-path required for pipeline mode")
            sys.exit(1)
        # Decorator ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        PipelineDecorator.run_locally()  # ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸
        run_training_pipeline(args.data_path)
    
    elif args.mode == "serve":
        serve_model(
            model_id=args.model_id,
            port=args.port
        )
    
    elif args.mode == "compare":
        if not args.model_ids:
            print("âŒ --model-ids required for compare mode")
            sys.exit(1)
        model_ids = args.model_ids.split(",")
        compare_models(model_ids)


if __name__ == "__main__":
    main()
