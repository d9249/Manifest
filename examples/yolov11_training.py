"""
ClearML YOLOv11 Training Example
================================
YOLOv11 ê°ì²´ íƒì§€ ëª¨ë¸ í•™ìŠµ ì˜ˆì œ

Features:
- ClearML ì‹¤í—˜ ì¶”ì  ë° ì•„í‹°íŒ©íŠ¸ ê´€ë¦¬
- ì›ê²© ì‹¤í–‰ ì§€ì› (ClearML Agent)
- í•˜ì´í¼íŒŒë¼ë¯¸í„° UI ìˆ˜ì • ê°€ëŠ¥

ì‚¬ìš©ë²•:
1. ë¡œì»¬ ì‹¤í–‰: python yolov11_training.py
2. ì›ê²© ëŒ€ê¸°ì—´ ì¶”ê°€: 
   clearml-task --project Manifest-Vision --name yolov11-training --script examples/yolov11_training.py --queue vision
"""

import os
import shutil
from pathlib import Path

# ClearML ì„í¬íŠ¸
from clearml import Task, Logger, Dataset

# ===========================================
# ClearML ì„œë²„ ì¸ì¦ ì„¤ì • (ngrok ì‚¬ìš© ì‹œ)
# ===========================================
Task.set_credentials(
    api_host="https://83f837d6923d.ngrok-free.app",
    web_host="http://localhost:8080",
    files_host="http://localhost:8081",
    key="Kj7mNp2xQw9rTs5vYb3uLc8h",
    secret="Xf4kMn7pQr2sTv5wYb8zCd3eGh6jKm9nPq2rSt5uVx8y"
)

# Ultralytics YOLO ì„í¬íŠ¸
from ultralytics import YOLO
import torch
import numpy as np

# ===========================================
# ClearML Task ì´ˆê¸°í™”
# ===========================================
task = Task.init(
    project_name="Manifest-Vision",
    task_name="YOLOv11-Object-Detection",
    task_type=Task.TaskTypes.training,
    tags=["yolov11", "object-detection", "vision", "ultralytics"]
)

# ===========================================
# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (ClearML UIì—ì„œ ìˆ˜ì • ê°€ëŠ¥)
# ===========================================
params = {
    # ëª¨ë¸ ì„¤ì •
    "model_variant": "yolo11s.pt",  # yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11l.pt, yolo11x.pt
    
    # í•™ìŠµ ì„¤ì •
    "epochs": 200,
    "batch_size": 32,
    "imgsz": 640,
    "optimizer": "AdamW",
    "learning_rate": 0.001,
    "patience": 20,  # Early stopping patience
    
    # ë°ì´í„° ì„¤ì •
    "data_yaml": "data/dataset.yaml",  # ë°ì´í„°ì…‹ YAML ê²½ë¡œ
    "cache": False,
    "workers": 2,
    
    # ì¶œë ¥ ì„¤ì •
    "project_dir": "./runs",
    "experiment_name": "yolov11_train"
}
task.connect(params)

# Logger ì´ˆê¸°í™”
logger = Logger.current_logger()


# ===========================================
# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì )
# ===========================================
def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì • (Linux/Colab í™˜ê²½ìš©)"""
    try:
        import matplotlib
        from matplotlib import font_manager, rcParams
        
        # ì‹œìŠ¤í…œì—ì„œ ë‚˜ëˆ” í°íŠ¸ ì°¾ê¸°
        font_paths = [
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/nanum/NanumGothic.ttf",
        ]
        
        font_path = None
        for path in font_paths:
            if os.path.exists(path):
                font_path = path
                break
        
        if font_path:
            font_manager.fontManager.addfont(font_path)
            rcParams["font.family"] = "NanumGothic"
            rcParams["axes.unicode_minus"] = False
            
            # Ultralytics í°íŠ¸ êµì²´
            ultra_font = os.path.expanduser("~/.config/Ultralytics/Arial.ttf")
            os.makedirs(os.path.dirname(ultra_font), exist_ok=True)
            shutil.copyfile(font_path, ultra_font)
            print(f"âœ“ Korean font configured: {ultra_font}")
        else:
            print("âš  Korean font not found, using default font")
            
    except Exception as e:
        print(f"âš  Font setup failed: {e}")


# ===========================================
# ë°ì´í„°ì…‹ ì¤€ë¹„
# ===========================================
def prepare_dataset():
    """ë°ì´í„°ì…‹ ì¤€ë¹„ ë° ê²€ì¦"""
    data_yaml = params["data_yaml"]
    
    # ClearML Datasetì—ì„œ ë‹¤ìš´ë¡œë“œ (ì˜µì…˜)
    # dataset = Dataset.get(dataset_project="Manifest-Vision", dataset_name="my-dataset")
    # data_path = dataset.get_local_copy()
    
    if not os.path.exists(data_yaml):
        print(f"âš  Warning: Dataset YAML not found at {data_yaml}")
        print("  Please ensure the dataset is properly configured.")
        print("  Expected YAML structure:")
        print("  ---")
        print("  path: /path/to/dataset")
        print("  train: images/train")
        print("  val: images/val")
        print("  names:")
        print("    0: class1")
        print("    1: class2")
        return None
    
    print(f"âœ“ Dataset YAML found: {data_yaml}")
    return data_yaml


# ===========================================
# í•™ìŠµ ê²°ê³¼ ë¡œê¹…
# ===========================================
def log_training_results(results, epoch=None):
    """í•™ìŠµ ê²°ê³¼ë¥¼ ClearMLì— ë¡œê¹…"""
    if results is None:
        return
    
    # í•™ìŠµ ë©”íŠ¸ë¦­ ë¡œê¹…
    if hasattr(results, 'results_dict'):
        for key, value in results.results_dict.items():
            if isinstance(value, (int, float)):
                logger.report_scalar(
                    title="Metrics",
                    series=key,
                    value=value,
                    iteration=epoch or 0
                )


# ===========================================
# ë©”ì¸ í•™ìŠµ í•¨ìˆ˜
# ===========================================
def main():
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = 0 if torch.cuda.is_available() else "cpu"
    print(f"Using device: {'GPU' if device == 0 else 'CPU'}")
    
    if torch.cuda.is_available():
        print(f"  GPU: {torch.cuda.get_device_name(0)}")
        print(f"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    # í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì )
    setup_korean_font()
    
    # ë°ì´í„°ì…‹ ì¤€ë¹„
    data_yaml = prepare_dataset()
    if data_yaml is None:
        print("âŒ Dataset not configured. Exiting.")
        return
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    project_dir = Path(params["project_dir"])
    project_dir.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "="*50)
    print("ğŸš€ Starting YOLOv11 Training")
    print("="*50)
    print(f"  Model: {params['model_variant']}")
    print(f"  Epochs: {params['epochs']}")
    print(f"  Batch Size: {params['batch_size']}")
    print(f"  Image Size: {params['imgsz']}")
    print(f"  Optimizer: {params['optimizer']}")
    print("="*50 + "\n")
    
    # ëª¨ë¸ ë¡œë“œ
    model = YOLO(params["model_variant"])
    
    # í•™ìŠµ ì‹¤í–‰
    results = model.train(
        data=data_yaml,
        epochs=params["epochs"],
        imgsz=params["imgsz"],
        batch=params["batch_size"],
        device=device,
        workers=params["workers"],
        cache=params["cache"],
        optimizer=params["optimizer"],
        patience=params["patience"],
        project=str(project_dir),
        name=params["experiment_name"],
        exist_ok=True,
        
        # ClearML ìë™ ë¡œê¹… í™œì„±í™”
        plots=True,
        save=True,
    )
    
    # í•™ìŠµ ì™„ë£Œ í›„ ê²°ê³¼ ë¡œê¹…
    print("\n" + "="*50)
    print("ğŸ“Š Training Results")
    print("="*50)
    
    # ìµœì¢… ë©”íŠ¸ë¦­ ê¸°ë¡
    if hasattr(results, 'results_dict'):
        for key, value in results.results_dict.items():
            if isinstance(value, (int, float)):
                logger.report_single_value(key, value)
                print(f"  {key}: {value:.4f}")
    
    # ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ
    best_model_path = project_dir / params["experiment_name"] / "weights" / "best.pt"
    last_model_path = project_dir / params["experiment_name"] / "weights" / "last.pt"
    
    if best_model_path.exists():
        task.upload_artifact("best_model", artifact_object=str(best_model_path))
        print(f"\nâœ“ Best model uploaded: {best_model_path}")
    
    if last_model_path.exists():
        task.upload_artifact("last_model", artifact_object=str(last_model_path))
        print(f"âœ“ Last model uploaded: {last_model_path}")
    
    # í•™ìŠµ ê²°ê³¼ ì´ë¯¸ì§€ ì—…ë¡œë“œ
    results_dir = project_dir / params["experiment_name"]
    for img_file in results_dir.glob("*.png"):
        logger.report_image(
            title="Training Results",
            series=img_file.stem,
            local_path=str(img_file)
        )
    
    print("\n" + "="*50)
    print("âœ… Training completed!")
    print("="*50)


if __name__ == "__main__":
    main()
